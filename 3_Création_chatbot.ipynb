{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des packages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import re\n",
    "import unicodedata \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import collections\n",
    "import csv\n",
    "import pickle\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # ou CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des vectoriseurs, de la fonction de normalisation et du dataFrame normalis√© : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_question = pd.read_pickle('dtm_question.pk')\n",
    "dtm_reponse = pd.read_pickle('dtm_reponse.pk')\n",
    "\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('french')\n",
    "stopwords = list(nltk_stopwords)\n",
    "stemmer=nltk.stem.SnowballStemmer('french')\n",
    "\n",
    "\n",
    "data = pd.read_csv('dataQR_normalize.csv', sep=';')\n",
    "def nettoyage_texte(txt):\n",
    "    #on met tout le texte en minuscule, et on remplce les retours √† la ligne par des espaces\n",
    "    txt = txt.lower().replace('\\n', ' ')\n",
    "\n",
    "    #on retire tous les accents \n",
    "    txt = unicodedata.normalize('NFD', txt).encode('ascii', 'ignore')\n",
    "\n",
    "    #on garde uniquement les caract√®res alphanum√©riques : \n",
    "    txt = re.sub('[^a-z_]', ' ', str(txt))\n",
    "    \n",
    "    #on retire les stops words\n",
    "    tokens = [w for w in txt.split() if (len(w)>2) and (w not in nltk_stopwords)]\n",
    "    \n",
    "    #pour avoir les mots racines\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_normalize</th>\n",
       "      <th>Reponse_normalize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment march vendr etap etap</td>\n",
       "      <td>vendr etap etap vendr articl cest simpl gratui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment march achet vinted tout etap</td>\n",
       "      <td>achet vinted tout etap trouv articl plait icon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment march vendr vinted gratuit</td>\n",
       "      <td>vendr vinted gratuit frais quand ajout vend ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment march comment partag retour dexperient...</td>\n",
       "      <td>comment partag retour dexperient vinted aim sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment march comment utilis centr aid</td>\n",
       "      <td>comment utilis centr aid centr daid trouv repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>connect narriv connect compt</td>\n",
       "      <td>narriv connect compt essai connect adress mail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>connect pourquoi compt ete bloqu</td>\n",
       "      <td>pourquoi compt ete bloqu privileg commun comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>connect pourquoi adress ete bloque</td>\n",
       "      <td>pourquoi adress ete bloque connect vinted mess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>connect comment chang mot pass</td>\n",
       "      <td>comment chang mot pass modifi mot pass cest si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>connect jessai inscrir vinted adress mail pris</td>\n",
       "      <td>jessai inscrir vinted adress mail pris lorsqu ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Question_normalize  \\\n",
       "0                        comment march vendr etap etap   \n",
       "1                 comment march achet vinted tout etap   \n",
       "2                   comment march vendr vinted gratuit   \n",
       "3    comment march comment partag retour dexperient...   \n",
       "4               comment march comment utilis centr aid   \n",
       "..                                                 ...   \n",
       "216                       connect narriv connect compt   \n",
       "217                   connect pourquoi compt ete bloqu   \n",
       "218                 connect pourquoi adress ete bloque   \n",
       "219                     connect comment chang mot pass   \n",
       "220     connect jessai inscrir vinted adress mail pris   \n",
       "\n",
       "                                     Reponse_normalize  \n",
       "0    vendr etap etap vendr articl cest simpl gratui...  \n",
       "1    achet vinted tout etap trouv articl plait icon...  \n",
       "2    vendr vinted gratuit frais quand ajout vend ar...  \n",
       "3    comment partag retour dexperient vinted aim sa...  \n",
       "4    comment utilis centr aid centr daid trouv repo...  \n",
       "..                                                 ...  \n",
       "216  narriv connect compt essai connect adress mail...  \n",
       "217  pourquoi compt ete bloqu privileg commun comme...  \n",
       "218  pourquoi adress ete bloque connect vinted mess...  \n",
       "219  comment chang mot pass modifi mot pass cest si...  \n",
       "220  jessai inscrir vinted adress mail pris lorsqu ...  \n",
       "\n",
       "[221 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-2615d5445af6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmy_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_most_sim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtextsimi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ecologie\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-2615d5445af6>\u001b[0m in \u001b[0;36mtextsimi\u001b[1;34m(texte)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtextsimi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexte\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'french'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "def textsimi(texte) :\n",
    "    sw = stopwords.words('french')\n",
    "        \n",
    "    dtm = dtm_question.transform(data['Question_normalize'])\n",
    "    req_vect = dtm_question.transform(texte)\n",
    "    \n",
    "    #os.remove('nom_fichier.txt')\n",
    "    query_corpus_sim = np.squeeze(cosine_similarity(dtm, req_vect))\n",
    "    idx_most_sim = np.argmax(query_corpus_sim)\n",
    "    return my_files[idx_most_sim]\n",
    "\n",
    "textsimi(\"ecologie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chatbot() : \n",
    "    #on r√©cup√®re la question pos√©e par l'utilisateur \n",
    "    phrase_user = input(\"Salut, comment puis-je t'aider ?\")\n",
    "    \n",
    "    #boucle while permettant la continuit√© du dialogue\n",
    "    #si l'utilisateur nous dit au revoir alors le programme s'arr√™te \n",
    "    while not re.search(r\"(.*)au revoir\", phrase_user, re.IGNORECASE):\n",
    "        #on normalise la phrase entr√©e par l'utilisateur \n",
    "        phrase_norm = nettoyage_texte(phrase_user)\n",
    "        \n",
    "        #on applique le vectoriseur des questions √† cette nouvelle phrase \n",
    "        phrase_vect_q = dtm_question.transform(phrase_norm)\n",
    "        \n",
    "        \n",
    "        os.remove('nom_fichier.txt')\n",
    "        query_corpus_sim = np.squeeze(cosine_similarity(dtm, req_vect))\n",
    "        idx_most_sim = np.argmax(query_corpus_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eliza():\n",
    "    # diff√©rentes regex auxquelles il faut faire attention en anglais\n",
    "    regex_not=r'n\\'t\\b'\n",
    "    regex_iam=r'\\'m\\b'\n",
    "    regex_re=r'\\'re\\b'\n",
    "    regex_ll=r'\\'ll\\b'\n",
    "    regex_ve=r'\\'ve\\b'\n",
    "    regex_s=r'\\'s\\b'\n",
    "    # liste des regex \n",
    "    liste_regexs = {regex_not:' not', regex_iam :' am', regex_re:' are', regex_ll:' will', regex_ve:' have',regex_s:''}\n",
    "    \n",
    "    phrase_user = input(\"Hi, I'm ELIZA. I'm happy that you come to see me. What do you want to talk to me about?\")\n",
    "    \n",
    "    \n",
    "    # boucle while permettant la continuit√© du dialogue \n",
    "    # si l'utilisateur nous dit Goodbye alors le programme s'arr√™te\n",
    "    while not re.search(r\"Good(.*)bye\", phrase_user, re.IGNORECASE):    \n",
    "        # g√©rer les exceptions et la ponctuation\n",
    "        for regex, replace in liste_regexs.items():\n",
    "            phrase = re.sub(regex, replace, phrase_user)\n",
    "\n",
    "        mots_user = re.sub(r'[!\"#$%&\\'\\(\\)\\*\\+,-\\./:;<=>\\?@\\[\\]^_`\\{\\|\\}~]', ' ', phrase).lower().split()\n",
    "        \n",
    "        \n",
    "        # on enl√®ve les mots qui n'ont pas de sens particulier dans la phrase\n",
    "        stopwordsEng = set(stopwords.words(\"english\"))\n",
    "        not_stopwords = ['My', 'you', 'me', 'Why', 'I']\n",
    "        final_stop_words = set([word for word in stopwordsEng if word not in not_stopwords])\n",
    "\n",
    "        liste_mots_sans_stopWord = [mot for mot in texte_test if mot not in final_stop_words]\n",
    "\n",
    "        phrase_sans_stopWord = \" \".join(liste_mots_sans_stopWord)\n",
    "        \n",
    "\n",
    "        # r√©ponses possibles d'Eliza\n",
    "        repEliza = {r'(.*)':  [\"Please tell me more.\",\n",
    "                              \"Let's change focus a bit... Tell me about your family.\"],\n",
    "                    r'My(.*)':\n",
    "                              [ \"I see.\",\n",
    "                                \"Why do you say that ?\",\n",
    "                                \"How do you feel?\"],\n",
    "                    r'You(.*)':\n",
    "                              [  \"We should be discussing you, not me.\",\n",
    "                                \"Why do you say that about me?\"],\n",
    "                    r'Why(.*)':\n",
    "                              [  \"Why don't you tell me the reason why ?\",\n",
    "                                \"Why do you think that?\" ],\n",
    "                    r'I want(.*)':\n",
    "                              [  \"What would it mean to you if you got one?\",\n",
    "                                \"Why do you want ?\",\n",
    "                                \"What would you do if you got one?\",\n",
    "                                \"If you got one, then what would you do?\"],\n",
    "                    r'(.*)friend(.*)'üòû\"Tell me more about your friends.\",\n",
    "                                      \"When you think of a friend, what comes to mind?\",\n",
    "                                      \"Why don‚Äôt you tell me about a childhood friend?\"],\n",
    "                    r'(.*)mother(.*)':\n",
    "                              [  \"Tell me more about your mother.\",\n",
    "                                \"What was your relationship with your mother like?\",\n",
    "                                \"How do you feel about your mother?\"],\n",
    "                    r'(.*)father(.*)':\n",
    "                              [  \"Tell me more about your father.\",\n",
    "                                \"How did your father make you feel?\",\n",
    "                                \"Does your relationship with your father relate to your feelings today?\"],\n",
    "                    r'(.*)child(.*)':\n",
    "                              [  \"Did you have close friends as a child?\",\n",
    "                                \"What is your favorite childhood memory?\",\n",
    "                                \"Do you remember any dreams or nightmares from childhood?\",\n",
    "                                \"How do you think your childhood experiences relate to your feelings today?\"],\n",
    "                   \n",
    "                     r'Hello(.*)': [\"Hello‚Ä¶ I‚Äôm glad you could drop by today.\",\n",
    "                                  \"Hi there‚Ä¶ how are you today?\",\n",
    "                                  \"Hello, how are you feeling today?\"]}\n",
    "        # Les r√©ponses ont √©t√© mises, dans l'ordre de la regex la moins importante √† la plus \n",
    "        # importante, afin que si l'utilisateur commence avec Hello mais aussi un autre √©l√©ment des r√©ponses\n",
    "        # Eliza, alors il selectionnera une phrase qui a pour cl√© le regex Hello.\n",
    "        \n",
    "        reponse=None\n",
    "        while reponse==None:\n",
    "            for key in repEliza.keys():\n",
    "                if re.search(key, phrase_sans_stopWord, re.IGNORECASE):\n",
    "                    reponse = random.choice(repEliza[key])\n",
    "        print(reponse) \n",
    "                            \n",
    "        phrase_user = input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
